# Generic configuration for Kafka producer.
properties:
  # Kafka key serializer. Default to ByteArraySerializer
  key.serializer: ${kafka-producer.key.serializer:org.apache.kafka.common.serialization.ByteArraySerializer}
  # Kafka value serializer. Default to ByteArraySerializer
  value.serializer: ${kafka-producer.value.serializer:org.apache.kafka.common.serialization.ByteArraySerializer}
  # This value is a string, if using 1 or 0, you must use '1' or '0' as the value
  acks: ${kafka-producer.acks:all}
  # Kafka bootstrap servers. Default to localhost:9092
  bootstrap.servers: ${kafka-producer.bootstrap.servers:localhost:9092}
  # Buffer size for unsent records. Default to 33554432
  buffer.memory: ${kafka-producer.buffer.memory:33554432}
  # Retry times for producer. Default to 3
  retries: ${kafka-producer.retries:3}
  # Batch size. Default to 16KB
  batch.size: ${kafka-producer.batch.size:16384}
  # Linger time. Default to 1ms
  linger.ms: ${kafka-producer.linger.ms:1}
  # max in-flight requests per connection. Default to 5
  max.in.flight.requests.per.connection: ${kafka-producer.max.in.flight.requests.per.connection:5}
  # enable idempotence. Default to true
  enable.idempotence: ${kafka-producer.enable.idempotence:false}
  # Confluent schema registry url
  schema.registry.url: ${kafka-producer.schema.registry.url:http://localhost:8081}
  # Schema registry identity cache size
  schema.registry.cache: ${kafka-producer.schema.registry.cache:100}
  # Schema registry auto register schema indicator for streams application.
  # If true, the first request will register the schema auto automatically.
  schema.registry.auto.register.schemas: ${kafka-producer.schema.registry.auto.register.schemas:true}
  # Schema registry client truststore location, use the following two properties only if schema registry url is https.
  schema.registry.ssl.truststore.location: ${kafka-producer.schema.registry.ssl.truststore.location:/config/client.truststore}
  # Schema registry client truststore password
  schema.registry.ssl.truststore.password: ${kafka-producer.schema.registry.ssl.truststore.password:password}
  # security configuration for enterprise deployment
  security.protocol: ${kafka-producer.security.protocol:SASL_SSL}
  # SASL mechanism for authentication
  sasl.mechanism: ${kafka-producer.sasl.mechanism:PLAIN}
  sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${kafka-producer.username:username}\" password=\"${kafka-producer.password:password}\";
  # SSL truststore location for secure communication
  ssl.truststore.location: ${kafka-producer.ssl.truststore.location:/config/client.truststore}
  # SSL truststore password for secure communication
  ssl.truststore.password: ${kafka-producer.ssl.truststore.password:password}
  # SSL endpoint identification algorithm for secure communication. This is used to verify the hostname of the server against the certificate presented by the server.
  ssl.endpoint.identification.algorithm: ${kafka-producer.ssl.endpoint.identification.algorithm:also-name}
  # Client rack identifier for Kafka producer. Default to rack1
  client.rack: ${kafka-producer.client.rack:rack1}
  basic.auth.user.info: ${kafka-producer.username:username}:${kafka-producer.password:password}
  # basic authentication credentials source for the schema registry. Default to USER_INFO
  basic.auth.credentials.source: ${kafka-producer.basic.auth.credentials.source:USER_INFO}
  # If you have message that is bigger than 1 MB to produce, increase this value.
  max.request.size: ${kafka-producer.max.request.size:1048576}
  # Any additional properties that are not defined in the schema can be added here.
  # This is useful for custom configurations that are not part of the standard Kafka producer properties.
  additionalKafkaProperties: ${kafka-producer.additionalKafkaProperties:}
# The default topic for the producer. Only certain producer implementation will use it.
topic: ${kafka-producer.topic:portal-event}
# Default key format if no schema for the topic value
keyFormat: ${kafka-producer.keyFormat:jsonschema}
# Default value format if no schema for the topic value
valueFormat: ${kafka-producer.valueFormat:jsonschema}
# If open tracing is enable. traceability, correlation and metrics should not be in the chain if opentracing is used.
injectOpenTracing: ${kafka-producer.injectOpenTracing:false}
# Inject serviceId as callerId into the http header for metrics to collect the caller. The serviceId is from server.yml
injectCallerId: ${kafka-producer.injectCallerId:false}
# If audit is enabled, the producer will send the audit message to the audit topic.
auditEnabled: ${kafka-producer.auditEnabled:true}
# Audit log destination topic or logfile. Default to topic
auditTarget: ${kafka-producer.auditTarget:logfile}
# The consumer audit topic name if the auditTarget is topic
auditTopic: ${kafka-producer.auditTopic:sidecar-audit}
