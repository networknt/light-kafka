---
batchSize: 16384
lingerMs: 1
bufferMemory: 33554432
keySerializer: org.apache.kafka.common.serialization.ByteArraySerializer
valueSerializer: org.apache.kafka.common.serialization.ByteArraySerializer
keyDeSerializer: org.apache.kafka.common.serialization.ByteArraySerializer
valueDeSerializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
sessionTimeout: 30000
autoOffsetreset: earliest
enableAutoCommit: false
bootstrapServers: kafka:9092
topic: portal-event
# every server instance will have a unique transactionId
transactionId: T1000
transactionTimeoutMs: 900000
transactionalIdExpirationMs: 2073600000

# if open tracing is enable. traceability, correlation and metrics should not be in the chain if opentracing is used.
injectOpenTracing: ${client.injectOpenTracing:false}
# inject serviceId as callerId into the http header for metrics to collect the caller. The serviceId is from server.yml
injectCallerId: ${client.injectCallerId:false}


# When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. If 'false',
# producer retries due to broker failures, etc., may write duplicates of the retried message in the stream. Note that
# enabling idempotence requires <code>max.in.flight.requests.per.connection</code> to be less than or equal to 5,
# <code>retries</code> to be greater than 0 and <code>acks</code> must be 'all'. If these values are not explicitly set
# by the user, suitable values will be chosen. If incompatible values are set, a <code>ConfigException</code> will be thrown.
enableIdempotence: ${kafka-producer.enableIdempotence:true}
# The number of acknowledgments the producer requires the leader to have received before considering a request complete.
# This controls the  durability of records that are sent. The following settings are allowed:  <ul> <li><code>acks=0</code>
# If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately
# added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case,
# and the <code>retries</code> configuration will not take effect (as the client won't generally know of any failures). The
# offset given back for each record will always be set to <code>-1</code>. <li><code>acks=1</code> This will mean the leader
# will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this
# case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the
# record will be lost. <li><code>acks=all</code> This means the leader will wait for the full set of in-sync replicas to
# acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains
# alive. This is the strongest available guarantee. This is equivalent to the acks=-1 setting.</ul>
acks: ${kafka-producer.acks:all}
# Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially
# transient error. Note that this retry is no different than if the client resent the record upon receiving the error.
# Allowing retries without setting <code>max.in.flight.requests.per.connection</code> to 1 will potentially change the
# ordering of records because if two batches are sent to a single partition, and the first fails and is retried but
# the second succeeds, then the records in the second batch may appear first. Note additionally that produce requests
# will be failed before the number of retries has been exhausted if the timeout configured by <code>delivery.timeout.ms</code>
# expires first before successful acknowledgement. Users should generally prefer to leave this config unset and instead use
# <code>delivery.timeout.ms</code> to control retry behavior.
retries: ${kafka-producer.retries:0}
# The maximum number of unacknowledged requests the client will send on a single connection before blocking. Note that if
# this setting is set to be greater than 1 and there are failed sends, there is a risk of message re-ordering due to retries
# (i.e., if retries are enabled).
maxInFlightRequestsPerConnection: ${kafka-producer.maxInFlightRequestsPerConnection:5}
